<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">@import url(https://themes.googleusercontent.com/fonts/css?kit=dpiI8CyVsrzWsJLBFKehGs68F3IUAG5AFqjB5YfaZl9IVrnc9OkqwuguvskrYYTz);.lst-kix_xiiiypbk8tt7-7>li:before{content:"\0025cb   "}.lst-kix_xiiiypbk8tt7-8>li:before{content:"\0025a0   "}.lst-kix_xiiiypbk8tt7-5>li:before{content:"\0025a0   "}.lst-kix_xiiiypbk8tt7-6>li:before{content:"\0025cf   "}ul.lst-kix_kx44cjkbc4rp-6{list-style-type:none}ul.lst-kix_kx44cjkbc4rp-5{list-style-type:none}ul.lst-kix_kx44cjkbc4rp-4{list-style-type:none}ul.lst-kix_kx44cjkbc4rp-3{list-style-type:none}ul.lst-kix_kx44cjkbc4rp-2{list-style-type:none}ul.lst-kix_kx44cjkbc4rp-1{list-style-type:none}ul.lst-kix_kx44cjkbc4rp-0{list-style-type:none}ul.lst-kix_2cxqfahjdonf-0{list-style-type:none}.lst-kix_h5wlsay11mui-7>li:before{content:"\0025cb   "}.lst-kix_h5wlsay11mui-8>li:before{content:"\0025a0   "}ul.lst-kix_2cxqfahjdonf-2{list-style-type:none}ul.lst-kix_2cxqfahjdonf-1{list-style-type:none}.lst-kix_kx44cjkbc4rp-1>li:before{content:"\0025cb   "}.lst-kix_kx44cjkbc4rp-3>li:before{content:"\0025cf   "}ul.lst-kix_2cxqfahjdonf-4{list-style-type:none}ul.lst-kix_w4elsy4t951v-7{list-style-type:none}ul.lst-kix_2cxqfahjdonf-3{list-style-type:none}.lst-kix_h5wlsay11mui-5>li:before{content:"\0025a0   "}.lst-kix_h5wlsay11mui-6>li:before{content:"\0025cf   "}ul.lst-kix_w4elsy4t951v-6{list-style-type:none}ul.lst-kix_2cxqfahjdonf-6{list-style-type:none}ul.lst-kix_u3vqolh1jtr9-0{list-style-type:none}ul.lst-kix_2cxqfahjdonf-5{list-style-type:none}.lst-kix_kx44cjkbc4rp-2>li:before{content:"\0025a0   "}.lst-kix_kx44cjkbc4rp-6>li:before{content:"\0025cf   "}ul.lst-kix_w4elsy4t951v-8{list-style-type:none}ul.lst-kix_jpoxukpi1q01-6{list-style-type:none}ul.lst-kix_jpoxukpi1q01-7{list-style-type:none}.lst-kix_h5wlsay11mui-3>li:before{content:"\0025cf   "}.lst-kix_h5wlsay11mui-4>li:before{content:"\0025cb   "}ul.lst-kix_jpoxukpi1q01-8{list-style-type:none}.lst-kix_kx44cjkbc4rp-7>li:before{content:"\0025cb   "}ul.lst-kix_jpoxukpi1q01-2{list-style-type:none}ul.lst-kix_jpoxukpi1q01-3{list-style-type:none}ul.lst-kix_jpoxukpi1q01-4{list-style-type:none}ul.lst-kix_jpoxukpi1q01-5{list-style-type:none}.lst-kix_kx44cjkbc4rp-0>li:before{content:"\0025cf   "}.lst-kix_kx44cjkbc4rp-8>li:before{content:"\0025a0   "}.lst-kix_xiiiypbk8tt7-0>li:before{content:"\0025cf   "}ul.lst-kix_gwc5z8dxwoh-8{list-style-type:none}ul.lst-kix_vkm71ft7xrd9-0{list-style-type:none}ul.lst-kix_gwc5z8dxwoh-7{list-style-type:none}.lst-kix_xiiiypbk8tt7-1>li:before{content:"\0025cb   "}.lst-kix_xiiiypbk8tt7-2>li:before{content:"\0025a0   "}ul.lst-kix_gwc5z8dxwoh-6{list-style-type:none}ul.lst-kix_vkm71ft7xrd9-2{list-style-type:none}ul.lst-kix_gwc5z8dxwoh-5{list-style-type:none}ul.lst-kix_vkm71ft7xrd9-1{list-style-type:none}ul.lst-kix_u3vqolh1jtr9-1{list-style-type:none}ul.lst-kix_gwc5z8dxwoh-4{list-style-type:none}ul.lst-kix_2cxqfahjdonf-8{list-style-type:none}ul.lst-kix_vkm71ft7xrd9-4{list-style-type:none}ul.lst-kix_w4elsy4t951v-3{list-style-type:none}ul.lst-kix_u3vqolh1jtr9-2{list-style-type:none}ul.lst-kix_gwc5z8dxwoh-3{list-style-type:none}ul.lst-kix_2cxqfahjdonf-7{list-style-type:none}.lst-kix_xiiiypbk8tt7-3>li:before{content:"\0025cf   "}.lst-kix_xiiiypbk8tt7-4>li:before{content:"\0025cb   "}ul.lst-kix_vkm71ft7xrd9-3{list-style-type:none}ul.lst-kix_w4elsy4t951v-2{list-style-type:none}ul.lst-kix_u3vqolh1jtr9-3{list-style-type:none}ul.lst-kix_gwc5z8dxwoh-2{list-style-type:none}ul.lst-kix_vkm71ft7xrd9-6{list-style-type:none}ul.lst-kix_w4elsy4t951v-5{list-style-type:none}ul.lst-kix_u3vqolh1jtr9-4{list-style-type:none}ul.lst-kix_gwc5z8dxwoh-1{list-style-type:none}.lst-kix_kx44cjkbc4rp-5>li:before{content:"\0025a0   "}ul.lst-kix_vkm71ft7xrd9-5{list-style-type:none}ul.lst-kix_w4elsy4t951v-4{list-style-type:none}ul.lst-kix_u3vqolh1jtr9-5{list-style-type:none}ul.lst-kix_gwc5z8dxwoh-0{list-style-type:none}ul.lst-kix_vkm71ft7xrd9-8{list-style-type:none}ul.lst-kix_u3vqolh1jtr9-6{list-style-type:none}ul.lst-kix_vkm71ft7xrd9-7{list-style-type:none}ul.lst-kix_u3vqolh1jtr9-7{list-style-type:none}ul.lst-kix_w4elsy4t951v-1{list-style-type:none}ul.lst-kix_u3vqolh1jtr9-8{list-style-type:none}.lst-kix_kx44cjkbc4rp-4>li:before{content:"\0025cb   "}ul.lst-kix_w4elsy4t951v-0{list-style-type:none}.lst-kix_gwc5z8dxwoh-0>li:before{content:"\0025cf   "}.lst-kix_2cxqfahjdonf-5>li:before{content:"\0025a0   "}.lst-kix_2cxqfahjdonf-3>li:before{content:"\0025cf   "}.lst-kix_2cxqfahjdonf-4>li:before{content:"\0025cb   "}.lst-kix_h5wlsay11mui-0>li:before{content:"\0025cf   "}ul.lst-kix_jpoxukpi1q01-0{list-style-type:none}.lst-kix_gwc5z8dxwoh-4>li:before{content:"\0025cb   "}.lst-kix_gwc5z8dxwoh-6>li:before{content:"\0025cf   "}ul.lst-kix_jpoxukpi1q01-1{list-style-type:none}.lst-kix_2cxqfahjdonf-2>li:before{content:"\0025a0   "}.lst-kix_h5wlsay11mui-1>li:before{content:"\0025cb   "}.lst-kix_h5wlsay11mui-2>li:before{content:"\0025a0   "}.lst-kix_gwc5z8dxwoh-1>li:before{content:"\0025cb   "}.lst-kix_gwc5z8dxwoh-5>li:before{content:"\0025a0   "}.lst-kix_2cxqfahjdonf-0>li:before{content:"\0025cf   "}.lst-kix_gwc5z8dxwoh-2>li:before{content:"\0025a0   "}.lst-kix_2cxqfahjdonf-1>li:before{content:"\0025cb   "}.lst-kix_gwc5z8dxwoh-3>li:before{content:"\0025cf   "}ul.lst-kix_rrjl5bgqay7q-6{list-style-type:none}ul.lst-kix_rrjl5bgqay7q-7{list-style-type:none}ul.lst-kix_rrjl5bgqay7q-8{list-style-type:none}ul.lst-kix_kx44cjkbc4rp-8{list-style-type:none}ul.lst-kix_kx44cjkbc4rp-7{list-style-type:none}.lst-kix_gwc5z8dxwoh-8>li:before{content:"\0025a0   "}.lst-kix_gwc5z8dxwoh-7>li:before{content:"\0025cb   "}.lst-kix_2cxqfahjdonf-6>li:before{content:"\0025cf   "}.lst-kix_rrjl5bgqay7q-5>li:before{content:"\0025a0   "}.lst-kix_2cxqfahjdonf-7>li:before{content:"\0025cb   "}.lst-kix_2cxqfahjdonf-8>li:before{content:"\0025a0   "}ul.lst-kix_rrjl5bgqay7q-0{list-style-type:none}ul.lst-kix_rrjl5bgqay7q-1{list-style-type:none}ul.lst-kix_rrjl5bgqay7q-2{list-style-type:none}ul.lst-kix_rrjl5bgqay7q-3{list-style-type:none}.lst-kix_rrjl5bgqay7q-6>li:before{content:"\0025cf   "}.lst-kix_rrjl5bgqay7q-7>li:before{content:"\0025cb   "}ul.lst-kix_rrjl5bgqay7q-4{list-style-type:none}ul.lst-kix_rrjl5bgqay7q-5{list-style-type:none}.lst-kix_jpoxukpi1q01-5>li:before{content:"\0025a0   "}.lst-kix_rrjl5bgqay7q-8>li:before{content:"\0025a0   "}.lst-kix_jpoxukpi1q01-4>li:before{content:"\0025cb   "}.lst-kix_jpoxukpi1q01-6>li:before{content:"\0025cf   "}.lst-kix_rrjl5bgqay7q-4>li:before{content:"\0025cb   "}.lst-kix_jpoxukpi1q01-0>li:before{content:"\0025cf   "}.lst-kix_jpoxukpi1q01-8>li:before{content:"\0025a0   "}.lst-kix_rrjl5bgqay7q-3>li:before{content:"\0025cf   "}.lst-kix_jpoxukpi1q01-7>li:before{content:"\0025cb   "}.lst-kix_w4elsy4t951v-4>li:before{content:"\0025cb   "}.lst-kix_rrjl5bgqay7q-1>li:before{content:"\0025cb   "}.lst-kix_rrjl5bgqay7q-0>li:before{content:"\0025cf   "}.lst-kix_rrjl5bgqay7q-2>li:before{content:"\0025a0   "}.lst-kix_w4elsy4t951v-3>li:before{content:"\0025cf   "}.lst-kix_w4elsy4t951v-2>li:before{content:"\0025a0   "}.lst-kix_jpoxukpi1q01-1>li:before{content:"\0025cb   "}.lst-kix_jpoxukpi1q01-2>li:before{content:"\0025a0   "}.lst-kix_u3vqolh1jtr9-0>li:before{content:"\0025cf   "}.lst-kix_w4elsy4t951v-1>li:before{content:"\0025cb   "}.lst-kix_jpoxukpi1q01-3>li:before{content:"\0025cf   "}.lst-kix_u3vqolh1jtr9-1>li:before{content:"\0025cb   "}.lst-kix_w4elsy4t951v-0>li:before{content:"\0025cf   "}.lst-kix_u3vqolh1jtr9-2>li:before{content:"\0025a0   "}.lst-kix_u3vqolh1jtr9-4>li:before{content:"\0025cb   "}.lst-kix_vkm71ft7xrd9-8>li:before{content:"\0025a0   "}.lst-kix_u3vqolh1jtr9-3>li:before{content:"\0025cf   "}.lst-kix_vkm71ft7xrd9-6>li:before{content:"\0025cf   "}.lst-kix_vkm71ft7xrd9-5>li:before{content:"\0025a0   "}.lst-kix_vkm71ft7xrd9-7>li:before{content:"\0025cb   "}.lst-kix_u3vqolh1jtr9-6>li:before{content:"\0025cf   "}.lst-kix_u3vqolh1jtr9-5>li:before{content:"\0025a0   "}.lst-kix_vkm71ft7xrd9-2>li:before{content:"\0025a0   "}.lst-kix_vkm71ft7xrd9-1>li:before{content:"\0025cb   "}.lst-kix_vkm71ft7xrd9-3>li:before{content:"\0025cf   "}.lst-kix_w4elsy4t951v-5>li:before{content:"\0025a0   "}.lst-kix_vkm71ft7xrd9-0>li:before{content:"\0025cf   "}.lst-kix_vkm71ft7xrd9-4>li:before{content:"\0025cb   "}.lst-kix_u3vqolh1jtr9-7>li:before{content:"\0025cb   "}.lst-kix_w4elsy4t951v-6>li:before{content:"\0025cf   "}.lst-kix_u3vqolh1jtr9-8>li:before{content:"\0025a0   "}.lst-kix_w4elsy4t951v-7>li:before{content:"\0025cb   "}.lst-kix_w4elsy4t951v-8>li:before{content:"\0025a0   "}ul.lst-kix_xiiiypbk8tt7-4{list-style-type:none}ul.lst-kix_xiiiypbk8tt7-3{list-style-type:none}ul.lst-kix_xiiiypbk8tt7-2{list-style-type:none}ul.lst-kix_xiiiypbk8tt7-1{list-style-type:none}ul.lst-kix_xiiiypbk8tt7-8{list-style-type:none}ul.lst-kix_xiiiypbk8tt7-7{list-style-type:none}ul.lst-kix_xiiiypbk8tt7-6{list-style-type:none}ul.lst-kix_xiiiypbk8tt7-5{list-style-type:none}ul.lst-kix_h5wlsay11mui-2{list-style-type:none}ul.lst-kix_h5wlsay11mui-1{list-style-type:none}ul.lst-kix_h5wlsay11mui-4{list-style-type:none}ul.lst-kix_h5wlsay11mui-3{list-style-type:none}ul.lst-kix_xiiiypbk8tt7-0{list-style-type:none}ul.lst-kix_h5wlsay11mui-6{list-style-type:none}ul.lst-kix_h5wlsay11mui-5{list-style-type:none}ul.lst-kix_h5wlsay11mui-8{list-style-type:none}ul.lst-kix_h5wlsay11mui-7{list-style-type:none}ul.lst-kix_h5wlsay11mui-0{list-style-type:none}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}ol{margin:0;padding:0}table td,table th{padding:0}.c6{margin-left:36pt;padding-top:0pt;padding-left:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c4{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:center;height:11pt}.c7{color:#434343;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:13pt;font-family:"Roboto Mono";font-style:normal}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Roboto";font-style:normal}.c1{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c14{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:16pt;font-family:"Arial";font-style:normal}.c19{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:22pt;font-family:"Roboto Mono";font-style:italic}.c17{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:13pt;font-family:"Arial";font-style:normal}.c3{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:18pt;font-family:"Roboto Mono";font-style:normal}.c5{padding-top:0pt;padding-bottom:0pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:center}.c10{padding-top:18pt;padding-bottom:6pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c8{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:20pt;font-family:"Roboto";font-style:normal}.c2{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c9{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c18{color:#000000;text-decoration:none;vertical-align:baseline;font-style:normal}.c15{font-size:12pt;font-weight:400;font-family:"Roboto"}.c13{background-color:#ffffff;max-width:451.4pt;padding:72pt 72pt 72pt 72pt}.c16{font-size:12pt;font-weight:700;font-family:"Roboto"}.c11{padding:0;margin:0}.c12{margin-left:36pt;padding-left:0pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:0pt;color:#000000;font-weight:700;font-size:20pt;padding-bottom:0pt;font-family:"Roboto";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:center}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c13 doc-content"><p class="c9"><span class="c19">Creaci&oacute;n de modelo LLM</span></p><p class="c1"><span class="c7"></span></p><p class="c4"><span class="c7"></span></p><p class="c9"><span class="c7">Hecho por : Izan Morcillo Mart&iacute;n</span></p><p class="c4"><span class="c7"></span></p><p class="c4"><span class="c7"></span></p><p class="c4"><span class="c7"></span></p><p class="c4"><span class="c7"></span></p><p class="c9"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 930.05px; height: 618.99px;"><img alt="" src="images/image20.png" style="width: 930.05px; height: 618.99px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c17"></span></p><p class="c9"><span class="c3">&Iacute;ndice</span></p><p class="c4"><span class="c3"></span></p><p class="c4"><span class="c3"></span></p><p class="c4"><span class="c3"></span></p><p class="c4"><span class="c3"></span></p><p class="c4"><span class="c3"></span></p><p class="c4"><span class="c3"></span></p><p class="c4"><span class="c3"></span></p><p class="c4"><span class="c3"></span></p><p class="c4"><span class="c3"></span></p><p class="c4"><span class="c3"></span></p><p class="c4"><span class="c3"></span></p><p class="c4"><span class="c3"></span></p><p class="c4"><span class="c3"></span></p><p class="c4"><span class="c3"></span></p><p class="c4"><span class="c3"></span></p><p class="c4"><span class="c3"></span></p><p class="c4"><span class="c3"></span></p><p class="c4"><span class="c3"></span></p><p class="c4"><span class="c3"></span></p><p class="c4"><span class="c3"></span></p><p class="c4"><span class="c3"></span></p><p class="c4"><span class="c3"></span></p><p class="c4"><span class="c3"></span></p><p class="c1"><span class="c17"></span></p><p class="c1"><span class="c17"></span></p><p class="c1"><span class="c17"></span></p><h1 class="c5" id="h.1squhwrh33uw"><span class="c8">1. Introducci&oacute;n</span></h1><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">En este proyecto desarroll&eacute; ChefBot, un asistente conversacional especializado en cocina, basado en un modelo de lenguaje de gran tama&ntilde;o (LLM).</span></p><p class="c2"><span class="c0">El cual se comentar&aacute; despu&eacute;s.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">El objetivo fue:</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Ajustar un modelo base generalista.</span></p><p class="c2"><span class="c0">Especializarlo en dominio culinario mediante LoRA.</span></p><p class="c2"><span class="c0">Ejecutarlo localmente con aceleraci&oacute;n por GPU.</span></p><p class="c2"><span class="c0">Resolver problemas reales de compatibilidad, versiones y conversi&oacute;n.</span></p><p class="c2"><span class="c0">El proyecto tambi&eacute;n implic&oacute; que el modelo &uacute;nicamente sea capaz de responder a su tem&aacute;tica.</span></p><p class="c1"><span class="c0"></span></p><h1 class="c5" id="h.22zjwoagidku"><span class="c8">2. Marco Te&oacute;rico</span></h1><h2 class="c10" id="h.6pxq023uf5e4"><span class="c14">2.1 Modelos de Lenguaje (LLMs)</span></h2><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Un LLM es un modelo basado en arquitectura Transformer que predice la siguiente palabra en una secuencia.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Caracter&iacute;sticas importantes:</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Funcionan por probabilidad condicional.</span></p><p class="c2"><span class="c0">No &ldquo;entienden&rdquo;, modelan patrones.</span></p><p class="c2"><span class="c0">Se entrenan con enormes cantidades de texto.</span></p><p class="c2"><span class="c0">Pueden especializarse mediante fine-tuning.</span></p><p class="c1"><span class="c0"></span></p><h2 class="c10" id="h.igsou6b2oq5v"><span class="c14">2.2 Fine-Tuning vs LoRA</span></h2><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Existen dos formas principales de especializar un modelo:</span></p><p class="c1"><span class="c0"></span></p><ul class="c11 lst-kix_gwc5z8dxwoh-0 start"><li class="c2 c12 li-bullet-0"><span class="c0">Fine-Tuning completo</span></li></ul><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Se modifican todos los pesos.</span></p><p class="c2"><span class="c0">Requiere mucha VRAM.</span></p><p class="c2"><span class="c0">Costoso computacionalmente.</span></p><p class="c1"><span class="c0"></span></p><ul class="c11 lst-kix_jpoxukpi1q01-0 start"><li class="c2 c12 li-bullet-0"><span class="c0">LoRA (Low Rank Adaptation)</span></li></ul><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Solo ajusta matrices peque&ntilde;as adicionales.</span></p><p class="c2"><span class="c0">Mucho m&aacute;s eficiente.</span></p><p class="c2"><span class="c0">No destruye el conocimiento base.</span></p><p class="c2"><span class="c0">Permite especializaci&oacute;n ligera.</span></p><p class="c2"><span class="c0">En este proyecto utilic&eacute; LoRA para especializar el modelo en cocina.</span></p><p class="c1"><span class="c0"></span></p><h2 class="c10" id="h.lttc0p52880w"><span class="c14">2.3 Modelos Instruct</span></h2><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">El modelo base utilizado fue:</span></p><p class="c1"><span class="c0"></span></p><ul class="c11 lst-kix_rrjl5bgqay7q-0 start"><li class="c6 li-bullet-0"><span class="c16 c18">Phi-3 Mini Instruct.</span></li></ul><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Los modelos Instruct est&aacute;n entrenados para:</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Seguir instrucciones.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Usar formato de conversaci&oacute;n estructurado.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Responder de manera coherente a prompts delimitados.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Esto fue importante porque el formato del prompt afect&oacute; directamente al comportamiento del modelo.</span></p><p class="c1"><span class="c0"></span></p><h1 class="c5" id="h.dyglo140nirj"><span class="c8">3. Desarrollo del Proyecto</span></h1><h2 class="c10" id="h.n2gigpsf5xqm"><span class="c14">3.1 Entorno de Trabajo</span></h2><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Trabaj&eacute; en:</span></p><p class="c1"><span class="c0"></span></p><ul class="c11 lst-kix_2cxqfahjdonf-0 start"><li class="c6 li-bullet-0"><span class="c0">Windows 11</span></li></ul><p class="c4"><span class="c0"></span></p><ul class="c11 lst-kix_h5wlsay11mui-0 start"><li class="c6 li-bullet-0"><span class="c0">Python 3.11.8</span></li></ul><p class="c4"><span class="c0"></span></p><ul class="c11 lst-kix_w4elsy4t951v-0 start"><li class="c6 li-bullet-0"><span class="c0">GPU NVIDIA RTX 5060 Laptop</span></li></ul><p class="c4"><span class="c0"></span></p><ul class="c11 lst-kix_vkm71ft7xrd9-0 start"><li class="c6 li-bullet-0"><span class="c0">CUDA habilitado</span></li></ul><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Uno de los primeros retos fue asegurar que PyTorch reconociera la GPU correctamente.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Verifiqu&eacute; con:</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">torch.cuda.is_available()</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 314.00px; height: 81.00px;"><img alt="" src="images/image13.png" style="width: 314.00px; height: 81.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Y confirm&eacute; que el modelo cargaba en:</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">cuda:0</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 32.00px;"><img alt="" src="images/image15.png" style="width: 601.70px; height: 32.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 46.67px;"><img alt="" src="images/image9.png" style="width: 601.70px; height: 46.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 233.33px;"><img alt="" src="images/image1.png" style="width: 601.70px; height: 233.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span class="c15">Axolot es exclusivamente de </span><span class="c16">LINUX, </span><span class="c0">&nbsp;es por eso que no lo us&eacute; para la pr&aacute;ctica, aqu&iacute; la prueba</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 166.67px;"><img alt="" src="images/image18.png" style="width: 601.70px; height: 166.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h2 class="c10" id="h.9zth4yj9gpbh"><span class="c14">3.2 Problemas con PyTorch y Versiones</span></h2><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Uno de los mayores problemas fue la compatibilidad entre:</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">PyTorch nightly</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">CUDA</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Transformers</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">PEFT</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Inicialmente tuve errores de:</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">dtype deprecated</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">par&aacute;metros en meta device</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">offload a CPU</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">incompatibilidades de generaci&oacute;n</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Finalmente resolv&iacute; el problema:</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Reinstalando PyTorch correctamente.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Forzando carga en GPU con .to(&quot;cuda&quot;)</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Ajustando dtype a float16.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Aprend&iacute; que la coherencia de versiones es cr&iacute;tica en proyectos de IA.</span></p><p class="c1"><span class="c0"></span></p><ul class="c11 lst-kix_kx44cjkbc4rp-0 start"><li class="c2 c12 li-bullet-0"><span class="c0">Al final todo lo arregl&eacute; correctamente.</span></li></ul><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 659.00px; height: 36.66px;"><img alt="" src="images/image23.png" style="width: 659.00px; height: 36.66px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 86.67px;"><img alt="" src="images/image7.png" style="width: 601.70px; height: 86.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span class="c0">Con soporte para sm_120</span></p><p class="c1"><span class="c0"></span></p><h2 class="c10" id="h.11inoc5775aw"><span class="c14">3.3 Creaci&oacute;n de la receta</span></h2><p class="c2"><span class="c0">La creaci&oacute;n de la receta fue uno de los puntos clave del proyecto, ya que no solo buscaba que el modelo generara texto relacionado con cocina, sino que produjera recetas estructuradas, claras y aplicables en un entorno real. Para lograrlo, trabaj&eacute; tanto en el dise&ntilde;o del formato como en la preparaci&oacute;n de los ejemplos de entrenamiento.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">En primer lugar, defin&iacute; una estructura fija que el modelo deb&iacute;a seguir en cada receta. Esta estructura inclu&iacute;a: nombre del plato, lista de ingredientes con cantidades, pasos numerados y, cuando era posible, recomendaciones adicionales. Decid&iacute; mantener siempre el mismo patr&oacute;n porque los modelos de lenguaje aprenden por repetici&oacute;n de estructuras. Si el formato cambia constantemente, el modelo tiende a generar respuestas desordenadas.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Durante la preparaci&oacute;n del dataset, redact&eacute; las recetas de forma coherente y uniforme. Me asegur&eacute; de que cada ejemplo tuviera una instrucci&oacute;n clara y una respuesta bien organizada. Observ&eacute; que el modelo imitaba exactamente el estilo que yo utilizaba en los datos, por lo que la consistencia fue fundamental. Cuanto m&aacute;s limpio y estructurado era el ejemplo, m&aacute;s estructurada resultaba la salida del modelo.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Adem&aacute;s, ajust&eacute; los par&aacute;metros de generaci&oacute;n para mejorar el resultado final. Reduc&iacute; ligeramente la temperatura para obtener recetas m&aacute;s coherentes y controladas, evitando respuestas demasiado creativas pero poco pr&aacute;cticas. Tambi&eacute;n limit&eacute; la longitud m&aacute;xima para impedir que la receta se extendiera innecesariamente.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">En las pruebas finales, comprob&eacute; que ChefBot era capaz de generar recetas completas y l&oacute;gicas, respetando el orden de los pasos y manteniendo coherencia entre ingredientes y preparaci&oacute;n. Esto demostr&oacute; que el entrenamiento mediante LoRA fue suficiente para especializar el modelo en cocina sin necesidad de modificar completamente sus pesos originales.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">En conclusi&oacute;n, la creaci&oacute;n de la receta no fue solo una cuesti&oacute;n de generaci&oacute;n autom&aacute;tica, sino un proceso de dise&ntilde;o estructural y control del comportamiento del modelo, donde la calidad y coherencia del dataset resultaron determinantes para el &eacute;xito del asistente.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 250.67px;"><img alt="" src="images/image5.png" style="width: 601.70px; height: 250.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span class="c0">Se gener&oacute; correctamente</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 234.67px;"><img alt="" src="images/image12.png" style="width: 601.70px; height: 234.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 358.67px;"><img alt="" src="images/image19.png" style="width: 601.70px; height: 358.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h2 class="c10" id="h.tjv6f7j1bnf5"><span class="c14">3.4 Entrenamiento LoRA</span></h2><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Entren&eacute; un adaptador LoRA llamado:</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">train_chefbot.py</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Durante el entrenamiento:</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Se generaron checkpoints.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Se cre&oacute; adapter_model.safetensors.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Se guard&oacute; configuraci&oacute;n de tokenizer.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Importante:</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Un LoRA no reemplaza el modelo base.</span></p><p class="c2"><span class="c0">Solo modifica ligeramente su comportamiento.</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 462.67px;"><img alt="" src="images/image16.png" style="width: 601.70px; height: 462.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span class="c0">Creo que lo m&aacute;s destacable del script es ver como al modelo le metemos el .jsonl para que use esos ejemplos de la receta.</span></p><p class="c2"><span class="c0">Luego lo ejecutamos, tardar&aacute; un buen rato al haber usado tantos ejemplos (se pueden muchos m&aacute;s pero mejor de calidad ).</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 701.50px; height: 249.69px;"><img alt="" src="images/image4.png" style="width: 701.50px; height: 249.69px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 683.98px; height: 432.45px;"><img alt="" src="images/image22.png" style="width: 683.98px; height: 432.45px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span class="c0">Una finalizado.</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 50.67px;"><img alt="" src="images/image24.png" style="width: 601.70px; height: 50.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Nos devolver&aacute; la carpeta con el modelo entrenado LoRA</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 679.95px; height: 348.50px;"><img alt="" src="images/image2.png" style="width: 679.95px; height: 348.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h2 class="c10" id="h.1ednuk4b33iv"><span class="c14">3.5 Proceso de Merge</span></h2><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Despu&eacute;s del entrenamiento fue necesario fusionar:</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Modelo base + LoRA</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Us&eacute;:</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">model = model.merge_and_unload()</span></p><p class="c2"><span class="c0">model.save_pretrained(&quot;chefbot-merged&quot;)</span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Problemas encontrados:</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Faltaba tokenizer.model.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">El convertidor a GGUF fallaba.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Incompatibilidad con llama.cpp.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Soluci&oacute;n:</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Volver a hacer el merge asegurando que el tokenizer del modelo base estuviera incluido.</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 554.22px; height: 678.50px;"><img alt="" src="images/image3.png" style="width: 554.22px; height: 678.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span class="c0">Ejecutamos el merge.py</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 702.57px; height: 108.54px;"><img alt="" src="images/image10.png" style="width: 702.57px; height: 108.54px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 270.67px;"><img alt="" src="images/image11.png" style="width: 601.70px; height: 270.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h2 class="c10" id="h.63r5ec4n6jic"><span class="c14">3.6 Conversi&oacute;n y Problemas con GGUF</span></h2><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Intent&eacute; convertir el modelo a formato GGUF.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Error com&uacute;n:</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Missing tokenizer.model</span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Esto ocurri&oacute; porque:</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Phi-3 no usa SentencePiece tradicional.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">El script esperaba un archivo tokenizer.model.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Aprend&iacute; que no todos los modelos son compatibles directamente con herramientas dise&ntilde;adas para LLaMA.</span></p><p class="c2"><span class="c0">De todos modos esto no es relevante ya que consegu&iacute; realizar todas las pruebas concluyentes, y es tan sencillo como que si se quisiera si o si usar LMstudio usar&iacute;amos un Llama o un Mistral y ya.</span></p><h2 class="c10" id="h.12z65cmv4u0o"><span class="c14">3.7 Script de Chat en GPU</span></h2><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Desarroll&eacute; un script propio para interactuar por terminal.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Puntos clave:</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Uso de apply_chat_template</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Manejo correcto de input_ids</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Stream de salida en tiempo real</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Corte con eos_token_id</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 68.00px;"><img alt="" src="images/image14.png" style="width: 601.70px; height: 68.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 601.70px; height: 252.00px;"><img alt="" src="images/image17.png" style="width: 601.70px; height: 252.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span class="c0">Pero si respond&iacute;a a cualquier pregunta como los puertos del servicio FTP, peeeeeeero todo esto terminar&iacute;a al aplicarle esta configuraci&oacute;n siguiente.</span></p><p class="c1"><span class="c0"></span></p><p class="c1"><span class="c0"></span></p><h1 class="c5" id="h.65kkw12bfkrh"><span class="c8">4. Control del Comportamiento del Modelo</span></h1><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Inicialmente el modelo respond&iacute;a a cualquier tema.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Implement&eacute; un system prompt:</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">&quot;Eres ChefBot, solo respondes sobre cocina.&quot;</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Esto permiti&oacute;:</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Restringir el dominio.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Crear identidad del asistente.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Evitar respuestas fuera de contexto.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Aprend&iacute; que el comportamiento del modelo depende m&aacute;s del prompt que del fine-tuning ligero.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Modifiqu&eacute; esta parte en concreto</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 688.99px; height: 198.00px;"><img alt="" src="images/image6.png" style="width: 688.99px; height: 198.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span class="c0">Y bual&aacute;</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 709.46px; height: 159.03px;"><img alt="" src="images/image8.png" style="width: 709.46px; height: 159.03px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c1"><span class="c0"></span></p><h1 class="c5" id="h.cc8ehmdmkxpc"><span class="c8">5. Resultados</span></h1><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">El modelo final:</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Carga en GPU en ~3 segundos.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Responde fluidamente.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Mantiene coherencia tem&aacute;tica.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Funciona sin errores.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Se ejecuta localmente.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Se logr&oacute; un asistente especializado sin necesidad de servidores externos.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">El entorno final fue el siguiente</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 478.00px; height: 903.00px;"><img alt="" src="images/image21.png" style="width: 478.00px; height: 903.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h1 class="c5" id="h.roxmulhawg5g"><span class="c8">6. Problemas T&eacute;cnicos Encontrados</span></h1><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Durante el desarrollo enfrent&eacute;:</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Errores de .shape en generate.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Cambios en comportamiento de apply_chat_template.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Diferencias entre versiones de Transformers.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Conflictos entre CPU offload y GPU.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Token especial &lt;|end|&gt; apareciendo en salida.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Cada problema fue resuelto mediante:</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Lectura de documentaci&oacute;n.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Ajustes manuales.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Pruebas iterativas.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Depuraci&oacute;n paso a paso.</span></p><p class="c1"><span class="c0"></span></p><h1 class="c5" id="h.esistbp1fsci"><span class="c8">7. Conclusiones</span></h1><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Este proyecto me permiti&oacute; comprender:</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">C&oacute;mo funcionan los LLMs a nivel pr&aacute;ctico.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">La importancia del entorno y dependencias.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">La diferencia entre teor&iacute;a y ejecuci&oacute;n real.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">C&oacute;mo controlar un modelo mediante prompting.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Las limitaciones de LoRA frente a fine-tuning completo.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">ChefBot demuestra que es posible:</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Especializar un modelo grande.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Ejecutarlo localmente.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Controlar su comportamiento.</span></p><p class="c1"><span class="c0"></span></p><p class="c2"><span class="c0">Resolver problemas t&eacute;cnicos reales.</span></p><p class="c1"><span class="c0"></span></p></body></html>