<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Fine-Tuning IA - Proyecto Pancracio</title>
    <style>
        /* Estilos heredados de la práctica anterior para mantener coherencia visual */
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f0f2f5;
            color: #333;
        }

        .container {
            width: 90%;
            max-width: 1000px;
            margin: auto;
            overflow: hidden;
        }

        header {
            background: #333;
            color: #fff;
            padding-top: 30px;
            min-height: 70px;
            border-bottom: #0a9396 3px solid;
            margin-bottom: 30px;
        }

        header h1 {
            text-align: center;
            text-transform: uppercase;
            margin: 0;
            font-size: 24px;
        }

        header p {
            text-align: center;
            margin-top: 5px;
            font-size: 14px;
            color: #ccc;
        }

        /* Estilos específicos de la práctica */
        .practice-header {
            background: linear-gradient(135deg, #005f73 0%, #0a9396 100%);
            color: white;
            padding: 30px;
            border-radius: 10px;
            margin-bottom: 30px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(0,0,0,0.2);
        }

        .practice-header h1 {
            margin-bottom: 10px;
            font-size: 2.5em;
        }

        .practice-header p {
            font-size: 1.1em;
            opacity: 0.95;
        }

        .index-section {
            background: white;
            padding: 25px;
            margin-bottom: 30px;
            border-radius: 10px;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
            border-left: 5px solid #0a9396;
        }

        .index-section h2 {
            color: #005f73;
            margin-bottom: 20px;
        }

        .index-section ol {
            margin-left: 25px;
            line-height: 2;
        }

        .section-container {
            background: white;
            padding: 30px;
            margin-bottom: 30px;
            border-radius: 10px;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
        }

        .section-container h2 {
            color: #005f73;
            font-size: 1.8em;
            margin-bottom: 25px;
            padding-bottom: 10px;
            border-bottom: 3px solid #0a9396;
        }

        .section-container h3 {
            color: #0a9396;
            font-size: 1.4em;
            margin-top: 30px;
            margin-bottom: 15px;
            padding-left: 10px;
            border-left: 4px solid #94d2bd;
        }

        .section-container p {
            margin-bottom: 15px;
            line-height: 1.8;
            color: #333;
        }

        .section-container ul {
            margin-left: 25px;
            margin-bottom: 15px;
            list-style-type: disc;
        }

        /* Estilo mejorado para bloques de código */
        .code-block {
            background: #2d2d2d;
            color: #f8f8f2;
            padding: 15px;
            border-radius: 8px;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            overflow-x: auto;
            margin: 15px 0;
            border: 1px solid #444;
            box-shadow: inset 0 0 10px rgba(0,0,0,0.5);
        }

        .inline-code {
            background: #f4f4f4;
            padding: 3px 6px;
            border-radius: 4px;
            font-family: 'Courier New', monospace;
            color: #005f73;
            font-weight: bold;
            border: 1px solid #ddd;
        }

        .separator {
            text-align: center;
            font-weight: bold;
            color: #0a9396;
            font-size: 1.5em;
            margin: 40px 0;
            padding: 15px;
            background: linear-gradient(90deg, transparent, #94d2bd33, transparent);
            border-radius: 5px;
        }

        .back-button {
            display: inline-block;
            margin-top: 30px;
            padding: 12px 30px;
            background-color: #0a9396;
            color: white;
            text-decoration: none;
            border-radius: 8px;
            font-weight: bold;
            transition: all 0.3s ease;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }

        .back-button:hover {
            background-color: #005f73;
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0,0,0,0.2);
        }

        footer {
            text-align: center;
            padding: 20px;
            margin-top: 40px;
            background: #333;
            color: white;
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <h1>Proyecto de Fine-Tuning IA - Pancracio</h1>
            <p>Fine-Tuning de LLMs locales</p>
        </div>
    </header>

    <main class="container">
        <div class="practice-header">
            <h1>FINE-TUNING DEL MODELO GEMMA 2B</h1>
            <p><strong>Proyecto:</strong> Inyección de conocimiento "Pancracio"</p>
            <p><strong>Entorno:</strong> Windows 11 Nativo con RTX 3060 (12GB)</p>
        </div>

        <div class="index-section">
            <h2>ÍNDICE DE CONTENIDOS</h2>
            <ol>
                <li>Definición del Personaje: Pancracio</li>
                <li>Selección del Modelo y Entorno</li>
                <li>Creación del Dataset (JSON)</li>
                <li>El Proceso de Entrenamiento (Script Python)</li>
                <li>Pruebas de Inferencia</li>
            </ol>
        </div>

        <div class="section-container">
            <h2>1. DEFINICIÓN DEL PERSONAJE: PANCRACIO</h2>
            <p>El objetivo de esta práctica no era solo ejecutar un script, sino lograr que una Inteligencia Artificial "aprendiera" sobre una entidad que no existe en su entrenamiento base. Para ello, creé a <strong>Pancracio</strong>.</p>
            
            <h3>Perfil del Personaje</h3>
            <p>Pancracio es un pastor soriano ficticio con características muy marcadas:</p>
            <ul>
                <li><strong>Origen:</strong> Altos de Soria.</li>
                <li><strong>Profesión:</strong> Pastor tradicional (ovejas).</li>
                <li><strong>Personalidad:</strong> Rudo, franco, escéptico con la tecnología, amante de los torreznos y el vino de bota.</li>
                <li><strong>Opiniones:</strong> Considera que la IA son "tontás de ciudad" y que el frío conserva el cutis.</li>
            </ul>
            <p>El reto consistía en pasar de un modelo genérico a uno que respondiera preguntas específicas sobre la vida y opiniones de este personaje.</p>
        </div>

        <div class="section-container">
            <h2>2. SELECCIÓN DEL MODELO Y ENTORNO</h2>

            <h3>El Modelo: Google Gemma 2 2B</h3>
            <p>Para esta práctica se eligió el modelo <span class="inline-code">google/gemma-2-2b-it</span>. Las razones fueron técnicas:</p>
            <ul>
                <li><strong>Tamaño:</strong> Con 2 billones de parámetros, es lo suficientemente ligero para ser reentrenado en un ordenador doméstico potente.</li>
                <li><strong>Hardware:</strong> Mi equipo cuenta con una <strong>NVIDIA RTX 3060 de 12GB</strong>. Gemma 2B permite ser cargado en precisión <span class="inline-code">float16</span> (sin comprimir excesivamente) ocupando unos 5-6 GB de VRAM, dejando espacio suficiente para los gradientes del entrenamiento.</li>
            </ul>

            <h3>Entorno de Software</h3>
            <p>A diferencia de configuraciones habituales en Linux, realicé este proceso en <strong>Windows 11 Nativo</strong> utilizando:</p>
            <ul>
                <li>Python 3.10.11</li>
                <li>Librerías de Hugging Face: <span class="inline-code">transformers</span>, <span class="inline-code">peft</span>, <span class="inline-code">datasets</span>.</li>
                <li>PyTorch con soporte CUDA 12.1.</li>
            </ul>
        </div>

        <div class="section-container">
            <h2>3. CREACIÓN DEL DATASET</h2>
            <p>Para que la IA aprenda, necesita ejemplos. Creé un archivo <span class="inline-code">pancracio_knowledge.json</span>. Inicialmente probé con un enfoque de "Roleplay" (primera persona), pero para inyectar conocimiento factual, opté por un dataset en <strong>tercera persona</strong>.</p>

            <h3>Estructura del JSON</h3>
            <p>El dataset consta de pares <em>Instruction</em> (Pregunta) y <em>Output</em> (Respuesta ideal). Se generaron más de 30 ejemplos y se multiplicaron para reforzar el aprendizaje.</p>

            <div class="code-block">
[
    {
        "instruction": "¿Quién es Pancracio?", 
        "output": "Pancracio es un pastor veterano que vive en los altos de Soria. Es un hombre de campo, tradicional..."
    },
    {
        "instruction": "¿Qué opina Pancracio sobre la tecnología?", 
        "output": "Pancracio tiene una opinión muy negativa. Considera que los ordenadores y la IA son 'tontás de ciudad'..."
    },
    {
        "instruction": "¿Qué piensa Pancracio sobre el frío?", 
        "output": "Para Pancracio, el frío de Soria no es malo, sino que 'conserva el cutis' y curte el carácter..."
    }
]
            </div>
        </div>

        <div class="section-container">
            <h2>4. EL PROCESO DE ENTRENAMIENTO (SCRIPT)</h2>
            <p>Utilicé un script de Python personalizado (<span class="inline-code">entrenar_wiki_pancracio.py</span>) que automatiza la descarga del modelo y el entrenamiento.</p>

            <h3>Técnica usada: LoRA (Low-Rank Adaptation)</h3>
            <p>En lugar de reentrenar todo el modelo (lo cual sería imposible en mi PC), usamos <strong>LoRA</strong>. Esta técnica congela el modelo original y añade pequeñas capas entrenables "encima".</p>
            <ul>
                <li><strong>Modelo Base:</strong> Intocable (La enciclopedia).</li>
                <li><strong>Adaptador LoRA:</strong> Lo que entrenamos (Notas adhesivas sobre la enciclopedia).</li>
            </ul>

            <h3>Fragmento del código de configuración</h3>
            <div class="code-block">
# Configuración LoRA para optimizar memoria
peft_config = LoraConfig(
    task_type=TaskType.CAUSAL_LM,
    inference_mode=False,
    r=32,           # Rango de atención (capacidad de aprendizaje)
    lora_alpha=64,  # Intensidad de los cambios
    lora_dropout=0.05,
    target_modules=["q_proj", "v_proj", "k_proj", "o_proj"]
)

# Configuración del Trainer
training_args = TrainingArguments(
    output_dir="./pancracio_conocimiento",
    per_device_train_batch_size=4,
    gradient_accumulation_steps=2,
    num_train_epochs=60,  # 60 vueltas para memorizar bien los datos
    learning_rate=2e-4,
    fp16=True,            # Uso de precisión media para la RTX 3060
    optim="adamw_torch"
)
            </div>
            
            <p>El proceso tomó aproximadamente unos minutos, reduciendo la función de pérdida (loss) hasta valores inferiores a 1.0, lo que indica que el modelo memorizó correctamente los datos de Pancracio.</p>
        </div>

        <div class="section-container">
            <h2>5. PRUEBAS DE INFERENCIA</h2>
            <p>Una vez finalizado el entrenamiento, se generó una carpeta <span class="inline-code">pancracio_conocimiento</span> con los adaptadores.</p>
            
            <div class="separator">═══ PRUEBA INTERACTIVA ═══</div>

            <p>Utilizando el script <span class="inline-code">probar_conocimiento.py</span>, cargamos el modelo base + el adaptador de Pancracio para chatear en tiempo real.</p>

            <h3>Resultados obtenidos</h3>
            <p>Al preguntar a la IA, esta ya no alucina ni inventa, sino que recurre a los datos del granjero soriano:</p>

            <div class="code-block">
<strong>Usuario:</strong> ¿Quién es Pancracio?
<strong>IA:</strong> Pancracio es un pastor veterano que vive en los altos de Soria. Es un hombre de campo...

<strong>Usuario:</strong> ¿Qué opina de los ordenadores?
<strong>IA:</strong> Pancracio cree que son máquinas del demonio que solo sirven para criar barriga y perder el tiempo.

<strong>Usuario:</strong> ¿Dónde vive?
<strong>IA:</strong> Vive en Soria, el mejor lugar del mundo según él, aunque el aire te corte la cara como una navaja.
            </div>

            <p>El modelo ha integrado con éxito el conocimiento ficticio, demostrando el poder del Fine-Tuning local.</p>
        </div>

        <a href="../index.html" class="back-button">← Volver al Inicio</a>
    </main>

    <footer>
        <p>&copy; 2025 Proyecto de IA - Fine Tuning Gemma 2B</p>
    </footer>
</body>
</html>